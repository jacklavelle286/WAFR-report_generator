AWSTemplateFormatVersion: 2010-09-09

Parameters:
  TemplateFile:
    Type: String
    Description: "The name of the template file in the S3 bucket."
    Default: "WellArchitectedTemplate.docx"
  
  ReportEmail: 
    Type: String
    Description: "The email address to receive the report notifications."
    Default: "example@gmail.com"

Resources:

  SNSReportTopic:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: "WARReportTopic"

  SNSReportSubscription:
    Type: AWS::SNS::Subscription
    Properties:
      Protocol: "email"
      TopicArn: !Ref SNSReportTopic
      Endpoint: !Ref ReportEmail

  dynamodbtable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: "wellarchitectedanswers"
      AttributeDefinitions:
        - AttributeName: "WorkloadId"
          AttributeType: "S"
        - AttributeName: "QuestionId"
          AttributeType: "S"
        - AttributeName: "Risk"  # Additional attribute for the GSI
          AttributeType: "S"
      KeySchema:
        - AttributeName: "WorkloadId"
          KeyType: "HASH"
        - AttributeName: "QuestionId"
          KeyType: "RANGE"
      ProvisionedThroughput:
        ReadCapacityUnits: 5
        WriteCapacityUnits: 5
      GlobalSecondaryIndexes:  # Optional: Define a GSI for the Risk attribute
        - IndexName: "RiskIndex"
          KeySchema:
            - AttributeName: "Risk"
              KeyType: "HASH"
          Projection:
            ProjectionType: "ALL"  # Include all attributes in the index
          ProvisionedThroughput:
            ReadCapacityUnits: 1
            WriteCapacityUnits: 1
  
  S3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub "csv-bucket-${AWS::AccountId}-${AWS::Region}"

  TemplateS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub "war-template-bucket-${AWS::AccountId}-${AWS::Region}"

  DestinationS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub "war-report-bucket-${AWS::AccountId}-${AWS::Region}"

  PutDynamoDBLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: "Allow"
            Principal:
              Service: "lambda.amazonaws.com"
            Action: "sts:AssumeRole"
      Description: "Generate report Lambda role."
      Policies:
        - PolicyName: lambda-role-generate-report
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "wellarchitected:GetLensReviewReport"
                  - "wellarchitected:GetWorkload"
                  - "wellarchitected:ListAnswers"
                Resource: "*"
              - Sid: "dynamodbAccess" 
                Effect: "Allow"
                Action: 
                  - "dynamodb:PutItem"
                Resource: 
                  - !Sub "arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/wellarchitectedanswers"
              - Sid: "Logging"  
                Effect: "Allow"
                Action: 
                  - "logs:CreateLogGroup"
                Resource: 
                  - !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              - Sid: "CreateLogStream"  
                Effect: "Allow"
                Action: 
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: 
                  - "*"  
      RoleName: put-dynamodb-lambda-role

  PutDynamoDBLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: "putDynamoDBLambda"
    
      Code:
        ZipFile: |
          import boto3
          import json
          import logging

          # Initialize logging
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def lambda_handler(event, context):
              logger.info(f"Received event: {json.dumps(event)}")

              # Initialize AWS clients
              wa_client = boto3.client('wellarchitected')
              dynamodb = boto3.resource('dynamodb')
              table = dynamodb.Table('wellarchitectedanswers')  # Ensure this matches your DynamoDB table name

              # Extract workload ID from the event
              workload_id = event['detail']['requestParameters']['WorkloadId']
              logger.info(f"Extracted WorkloadId: {workload_id}")

              try:
                  workload = wa_client.get_workload(WorkloadId=workload_id)
                  lenses = workload['Workload']['Lenses']
                  logger.info(f"Lenses for workload {workload_id}: {lenses}")

                  for lens_alias in lenses:
                      next_token = None
                      while True:
                          # Include the NextToken in the request if it's present
                          if next_token:
                              response = wa_client.list_answers(WorkloadId=workload_id, LensAlias=lens_alias, NextToken=next_token)
                          else:
                              response = wa_client.list_answers(WorkloadId=workload_id, LensAlias=lens_alias)

                          for answer in response['AnswerSummaries']:
                              question_id = answer['QuestionId']
                              selected_choices = answer.get('SelectedChoices', [])
                              notes = answer.get('Notes', '')
                              risk = answer.get('Risk', '')

                              # Filter for high and medium risk questions
                              if risk in ['HIGH', 'MEDIUM']:
                                  table.put_item(
                                      Item={
                                          'WorkloadId': workload_id,
                                          'QuestionId': question_id,
                                          'Risk': risk,
                                          'SelectedChoices': json.dumps(selected_choices),
                                          'Notes': notes
                                      }
                                  )
                                  logger.info(f"Processed {risk} risk answer for question {question_id} for lens {lens_alias} in workload {workload_id}")

                          # Check for a NextToken in the response and break the loop if not present
                          next_token = response.get('NextToken')
                          if not next_token:
                              break

              except Exception as e:
                  logger.error(f"Error processing workload {workload_id}: {str(e)}")
                  return {'statusCode': 500, 'body': json.dumps(f"Error processing workload {workload_id}: {str(e)}")}

              return {'statusCode': 200, 'body': json.dumps(f"Successfully processed high and medium risk questions for workload {workload_id}.")}


      Handler: index.lambda_handler
      Role: !GetAtt PutDynamoDBLambdaRole.Arn 
      Runtime: python3.12
      Timeout: 300
  
  GenerateCSVRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: "Allow"
            Principal:
              Service: "lambda.amazonaws.com"
            Action: "sts:AssumeRole"
      Description: "Generate CSV Lambda role."
      Policies:
        - PolicyName: lambda-role-generate-report
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Sid: "dynamodbAccess" 
                Effect: "Allow"
                Action: 
                  - "dynamodb:Query"
                  - "dynamodb:GetItem"
                Resource: 
                  - !Sub "arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/wellarchitectedanswers"
                  - !Sub "arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/wellarchitectedanswers/index/RiskIndex"
              - Sid: "s3Access" 
                Effect: "Allow"
                Action: 
                  - "s3:PutObject"
                Resource: 
                  - !Sub "arn:aws:s3:::${S3Bucket}/*"
              - Sid: "Logging"  
                Effect: "Allow"
                Action: 
                  - "logs:CreateLogGroup"
                Resource: 
                  - !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              - Sid: "CreateLogStream"  
                Effect: "Allow"
                Action: 
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: 
                  - "*"  
      RoleName: generate-csv-lambda-role

  GenerateCSVLambda:
    Type: AWS::Lambda::Function
    Properties:
      Environment:
        Variables:
          CSV_BUCKET: !Ref S3Bucket
          DYNAMODB_TABLE: !Ref dynamodbtable
      FunctionName: "generateCSVLambda"
      Role: !GetAtt GenerateCSVRole.Arn
      Runtime: python3.12
      Handler: index.lambda_handler
      Timeout: 300

    
      Code:
        ZipFile: |
          import boto3
          import csv
          import io
          import os

          def lambda_handler(event, context):
              # Extract the Workload ID from the event
              workload_id = event['workload_id']

              # Initialize AWS clients
              dynamodb = boto3.resource('dynamodb')
              s3 = boto3.client('s3')

              # Reference the DynamoDB table
              table = dynamodb.Table(os.environ['DYNAMODB_TABLE'])


              # Query the table for items related to the provided Workload ID
              response = table.query(
                  KeyConditionExpression='WorkloadId = :workload_id',
                  ExpressionAttributeValues={
                      ':workload_id': workload_id
                  }
              )

              # Generate CSV content
              csv_content = io.StringIO()
              csv_writer = csv.writer(csv_content)
              csv_writer.writerow(['WorkloadId', 'QuestionId', 'Risk', 'SelectedChoices', 'Notes'])  # Header

              for item in response['Items']:
                  csv_writer.writerow([item['WorkloadId'], item['QuestionId'], item['Risk'], item['SelectedChoices'], item['Notes']])

              # Upload CSV to S3 bucket
              s3.put_object(
                  Bucket=os.environ['CSV_BUCKET'],
                  Key=f'{workload_id}.csv',
                  Body=csv_content.getvalue()
              )

              # Return the S3 path of the uploaded CSV as output
              return {
                  'statusCode': 200,
                  'csv_s3_key': f'{workload_id}.csv'
              }

  GenerateFullReportLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: "Allow"
            Principal:
              Service: "lambda.amazonaws.com"
            Action: "sts:AssumeRole"
      Policies:
        - PolicyName: "generate-report-lambda-policy"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "s3:GetObject"
                Resource: 
                  - !Sub "arn:aws:s3:::${TemplateS3Bucket}/*"
                  - !Sub "arn:aws:s3:::${S3Bucket}/*"
              - Effect: "Allow"
                Action:
                  - "s3:PutObject"
                Resource: 
                  - !Sub "arn:aws:s3:::${DestinationS3Bucket}/*"
              - Effect: "Allow"
                Action:
                  - "wellarchitected:GetAnswer"
                Resource: "*"
              - Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: "arn:aws:logs:*:*:*"
      RoleName: generate-report-lambda-role
  
  GenerateFullReportLambda:
    Type: AWS::Lambda::Function
    Properties:
      Environment:
        Variables:
          TEMPLATE_BUCKET: !Ref TemplateS3Bucket
          DESTINATION_BUCKET: !Ref DestinationS3Bucket
          CSV_BUCKET: !Ref S3Bucket
          TEMPLATE_FILE: !Ref TemplateFile
      FunctionName: "generateFullReportLambda"
      Layers:
        - arn:aws:lambda:us-east-1:770693421928:layer:Klayers-p311-python-docx:3
      Code:
        ZipFile: |
          import boto3
          import csv
          import io
          import os
          from docx import Document
          from docx.shared import RGBColor
          from datetime import datetime
          import json

          def lambda_handler(event, context):
              # Define the S3 bucket names and file names from environment variables
              template_bucket = os.environ['TEMPLATE_BUCKET']
              csv_bucket = os.environ['CSV_BUCKET']
              output_bucket = os.environ['DESTINATION_BUCKET']
              csv_file_name = event['csv_file_name']
              template_file_name = os.environ['TEMPLATE_FILE']

              # Initialize S3 and Well-Architected client
              s3 = boto3.client('s3')
              wa_client = boto3.client('wellarchitected')

              # Download the template file from S3
              s3.download_file(template_bucket, template_file_name, '/tmp/template.docx')
              document = Document('/tmp/template.docx')

              # Download the CSV file from S3 and parse its content
              csv_object = s3.get_object(Bucket=csv_bucket, Key=csv_file_name)
              csv_content = csv_object['Body'].read().decode('utf-8')
              high_risk_items, medium_risk_items, workload_id = parse_csv_and_fetch_details(csv_content, wa_client)

              # Construct the report filename with the workload_id and current date
              date_str = datetime.now().strftime("%d.%m.%Y")
              report_filename = f"{date_str}-{workload_id}-report.docx"

              # Replace placeholders in the template with CSV data and set text color to white
              replace_placeholders(document, high_risk_items, medium_risk_items)

              # Save the modified document
              modified_file_path = '/tmp/modified_template.docx'
              document.save(modified_file_path)

              # Upload the modified document to the output S3 bucket
              with open(modified_file_path, 'rb') as modified_file:
                  s3.upload_fileobj(modified_file, output_bucket, report_filename)

              return {
                  'statusCode': 200,
                  'body': json.dumps({
                      'message': 'Report generated and uploaded successfully.',
                      'workloadId': workload_id,
                      'reportFilename': report_filename,
                      's3Bucket': output_bucket
                  })
              }

          def parse_csv_and_fetch_details(csv_content, wa_client):
              high_risk_items = []
              medium_risk_items = []
              workload_id = None  # Initialize workload_id
              csv_reader = csv.DictReader(io.StringIO(csv_content))

              for row in csv_reader:
                  if not workload_id:
                      workload_id = row['WorkloadId']  # Set the workload_id from the first row
                  question_details = wa_client.get_answer(
                      WorkloadId=row['WorkloadId'],
                      LensAlias='wellarchitected',
                      QuestionId=row['QuestionId']
                  )
                  question_text = question_details['Answer']['QuestionTitle']
                  pillar_id = format_pillar_id(question_details['Answer']['PillarId'])

                  formatted_text = f"{pillar_id}: {question_text}, Notes: {row['Notes']}"
                  if row['Risk'] == 'HIGH':
                      high_risk_items.append(formatted_text)
                  elif row['Risk'] == 'MEDIUM':
                      medium_risk_items.append(formatted_text)

              return high_risk_items, medium_risk_items, workload_id

          def format_pillar_id(pillar_id):
              # Special formatting for certain pillar IDs
              if pillar_id.lower() == 'costoptimization':
                  return 'Cost Optimization'
              elif pillar_id.lower() == 'operationalexcellence':
                  return 'Operational Excellence'
              else:
                  # General formatting for other pillar IDs
                  return ' '.join(word.capitalize() for word in pillar_id.split())

          def replace_placeholders(document, high_risk_items, medium_risk_items):
              for paragraph in document.paragraphs:
                  if '{{highrisk}}' in paragraph.text:
                      replace_paragraph_text_with_color(paragraph, "{{highrisk}}", "\n".join(high_risk_items))
                  elif '{{mediumrisk}}' in paragraph.text:
                      replace_paragraph_text_with_color(paragraph, "{{mediumrisk}}", "\n".join(medium_risk_items))

          def replace_paragraph_text_with_color(paragraph, placeholder, new_text):
              # Clear existing paragraph text
              paragraph.clear()

              # Add new run with specified text
              run = paragraph.add_run(new_text)

              # Set text color to white
              font = run.font
              font.color.rgb = RGBColor(255, 255, 255)

      Handler: index.lambda_handler
      Role: !GetAtt GenerateFullReportLambdaRole.Arn 
      Runtime: python3.11
      Timeout: 300
          
# everything below will be the presigned url function and role

  PresignedUrlRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: "Allow"
            Principal:
              Service: "lambda.amazonaws.com"
            Action: "sts:AssumeRole"
      Policies:
        - PolicyName: "presigned-lambda-policy"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "s3:GetObject"
                Resource: 
                  - !Sub "arn:aws:s3:::${DestinationS3Bucket}/*"
              - Effect: "Allow"
                Action:
                  - "sns:Publish"
                Resource: 
                  - !Sub "arn:aws:sns:${AWS::Region}:${AWS::AccountId}:*"
              - Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: "arn:aws:logs:*:*:*"
      RoleName: presigned-url-lambda-role 
  
  PresignedUrlLambda:
    Type: AWS::Lambda::Function
    Properties:
      Environment:
        Variables:
          SNS_TOPIC: !Ref SNSReportTopic
      FunctionName: "PresignedReportLambda"
      Code:
        ZipFile: |
          import boto3
          import os

          def lambda_handler(event, context):
              s3_client = boto3.client('s3')
              sns_client = boto3.client('sns')
              sns_topic_arn = os.environ['SNS_TOPIC']

              # Extract bucket name and object key from the event
              bucket_name = event['s3Bucket']
              object_key = event['reportFilename']

              # Generate a presigned URL for the report
              presigned_url = s3_client.generate_presigned_url('get_object',
                                                                Params={'Bucket': bucket_name, 'Key': object_key},
                                                                ExpiresIn=3600)  # URL expires in 1 hour

              # Publish the presigned URL to an SNS topic
              sns_response = sns_client.publish(
                  TopicArn=sns_topic_arn,
                  Message=f'New report available: {presigned_url}',
                  Subject='New Report Available'
              )

              return {
                  'statusCode': 200,
                  'body': f"Presigned URL published to SNS topic. SNS Message ID: {sns_response['MessageId']}"
              }

                    import boto3
                    import urllib.parse
                    from datetime import datetime, timedelta
                    import os

                    def lambda_handler(event, context):
                        s3_client = boto3.client('s3')
                        sns_client = boto3.client('sns')
                        sns_topic = os.environ['SNS_TOPIC']

                        # Extract bucket name and object key from the event
                        bucket_name = event['Records'][0]['s3']['bucket']['name']
                        object_key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], encoding='utf-8')

                        # Generate a presigned URL for the report
                        presigned_url = s3_client.generate_presigned_url('get_object',
                                                                          Params={'Bucket': bucket_name, 'Key': object_key},
                                                                          ExpiresIn=3600)  # URL expires in 1 hour

                        # Publish the presigned URL to an SNS topic
                        sns_topic_arn = 'sns_topic'
                        sns_response = sns_client.publish(
                            TopicArn=sns_topic_arn,
                            Message=f'New report available: {presigned_url}',
                            Subject='New Report Available'
                        )

                        return {
                            'statusCode': 200,
                            'body': f"Presigned URL published to SNS topic. SNS Message ID: {sns_response['MessageId']}"
                        }

      Handler: index.lambda_handler
      Role: !GetAtt PresignedUrlRole.Arn
      Runtime: python3.12
      Timeout: 300


  NewMilestoneRule:
    Type: AWS::Events::Rule
    Properties:
      Description: "Trigger Lambda function for new milestone in WAR Tool"
      EventBusName: default
      EventPattern:
        source:
          - "aws.wellarchitected"
        "detail-type":
          - "AWS API Call via CloudTrail"
        detail:
          eventSource:
            - "wellarchitected.amazonaws.com"
          eventName:
            - "CreateMilestone"
          requestParameters:
            WorkloadId:
              - exists: true
            MilestoneName:
              - exists: true

      State: "ENABLED"
      Targets:
        - Arn: !GetAtt PutDynamoDBLambda.Arn
          Id: "GenerateInitialReportRule"

  
  LambdaInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !GetAtt PutDynamoDBLambda.Arn
      Action: "lambda:InvokeFunction"
      Principal: "events.amazonaws.com"
      SourceArn: !GetAtt NewMilestoneRule.Arn
    DependsOn:
      - NewMilestoneRule
      - PutDynamoDBLambda

